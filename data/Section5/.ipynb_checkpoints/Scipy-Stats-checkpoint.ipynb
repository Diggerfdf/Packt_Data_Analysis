{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy\n",
    "\n",
    "The scipy package contains various toolboxes dedicated to common issues in scientific computing. Its different submodules correspond to different applications, such as interpolation, integration, optimization, image processing, statistics, special functions, etc. `scipy` is the core package for scientific routines in Python; it is meant to operate efficiently on numpy arrays, so that numpy and scipy work hand in hand.\n",
    "\n",
    "Here are some of the sub-packages contained in Scipy:\n",
    "\n",
    "* File input/output: scipy.io\n",
    "* Special functions: scipy.special\n",
    "* Linear algebra operations: scipy.linalg\n",
    "* Fast Fourier transforms: scipy.fftpack\n",
    "* Optimization and fit: scipy.optimize\n",
    "* Statistics and random numbers: scipy.stats\n",
    "* Interpolation: scipy.interpolate\n",
    "* Numerical integration: scipy.integrate\n",
    "* Signal processing: scipy.signal\n",
    "* Image processing: scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Statistics sub-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scipy.stats` sub-package contains a large number of probability distributions as well as a growing library of statistical functions. This is a great tool to have for any Data Analyst/Scientist using Python because Statistics is at the core of Data Science. \n",
    "\n",
    "In this section we learn how to perform common statistical computations with Python and use them to make sense of a dataset that contains information about alcohol consumption of teenagers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Alcohol consumption of students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import sqrt, arange\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we use a dataset containing information about Portuguese students from two public schools. This is a real world dataset that was collected in order to study alcohol consumption in young people and its effects on students' academic performance. The dataset was built from two sources: school reports and questionnaires.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "* 1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) \n",
    "* 2 sex - student's sex (binary: 'F' - female or 'M' - male) \n",
    "* 3 age - student's age (numeric: from 15 to 22) \n",
    "- 4 address - student's home address type (binary: 'U' - urban or 'R' - rural) \n",
    "- 5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) \n",
    "- 6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart) \n",
    "- 7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 -secondary education or 4 - higher education) \n",
    "- 8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 -secondary education or 4 - higher education) \n",
    "- 9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') \n",
    "- 10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') \n",
    "- 11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') \n",
    "- 12 guardian - student's guardian (nominal: 'mother', 'father' or 'other') \n",
    "- 13 traveltime - home to school travel time (numeric: 1 <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) \n",
    "- 14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) \n",
    "- 15 failures - number of past class failures (numeric: n if 1<=n<3, else 4) \n",
    "- 16 schoolsup - extra educational support (binary: yes or no) \n",
    "- 17 famsup - family educational support (binary: yes or no) \n",
    "- 18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) \n",
    "- 19 activities - extra-curricular activities (binary: yes or no) \n",
    "- 20 nursery - attended nursery school (binary: yes or no) \n",
    "- 21 higher - wants to take higher education (binary: yes or no) \n",
    "- 22 internet - Internet access at home (binary: yes or no) \n",
    "- 23 romantic - with a romantic relationship (binary: yes or no) \n",
    "- 24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) \n",
    "- 25 freetime - free time after school (numeric: from 1 - very low to 5 - very high) \n",
    "- 26 goout - going out with friends (numeric: from 1 - very low to 5 - very high) \n",
    "- 27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high) \n",
    "- 28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) \n",
    "- 29 health - current health status (numeric: from 1 - very bad to 5 - very good) \n",
    "- 30 absences - number of school absences (numeric: from 0 to 93) \n",
    "\n",
    "**these grades are related with the course subject:**\n",
    "\n",
    "- 31 G1 - first period grade (numeric: from 0 to 20) \n",
    "- 31 G2 - second period grade (numeric: from 0 to 20) \n",
    "- 32 G3 - final grade (numeric: from 0 to 20, output target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = pd.read_csv(\"../data/student/student.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demostration we are interested in 3 variables:\n",
    "\n",
    "1. Alcohol consumption level (we will create it and call it `acl`)\n",
    "2. Final grade for the course subject (`G3`)\n",
    "3. Gender of the student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.rename(columns={'sex':'gender'}, inplace=True)\n",
    "student['alcohol_index'] = (5*student['Dalc'] + 2*student['Walc'])/7\n",
    "# Alcohol consumption level\n",
    "student['acl'] = student['alcohol_index'] <= 2\n",
    "student['acl'] = student['acl'].map({True: 'Low', False: 'High'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval for the mean of the final grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate confidence intervals for means and for proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = student.shape[0]\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have a sample size that is much greater than 30, we can use the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) to calculate confidence intervals. According to this theorem we can calculate a confidence interval for the mean using the normal distribution.\n",
    "\n",
    "To get the confidence interval for the mean we need three numbers:\n",
    "\n",
    "1. Sample mean\n",
    "2. Standard error\n",
    "3. Confidence level\n",
    "\n",
    "Formula for the standar error:\n",
    "\n",
    "$$ SE = \\frac{s}{\\sqrt n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean_grade = student['G3'].mean()\n",
    "sample_mean_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_error_grades = student['G3'].std()/sqrt(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.interval(0.95, loc=sample_mean_grade, scale=std_error_grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate a confidence interval for the proportion of students with High Alcohol Consumption Level. Again we need 3 numbers:\n",
    "\n",
    "1. Sample proportion\n",
    "2. Standard error\n",
    "3. Confidence level\n",
    "\n",
    "For proportions the standars error is given by:\n",
    "\n",
    "$$ SE = \\sqrt \\frac{\\hat p (1 - \\hat p)}{n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student['acl'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prop = student['acl'].value_counts(normalize=True)['High']\n",
    "std_error_prop = sqrt(high_prop*(1-high_prop)/sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.interval(0.98, loc=high_prop, scale=std_error_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.25 (or 25.0%) seems like a good guess for the proportion of students with High Alcohol Consumption Levels in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are dozens of probability distributions available in the stats package for doing simulations of random variables or probability calculations. You can take a look at the reference [here](https://docs.scipy.org/doc/scipy/reference/stats.html)\n",
    "\n",
    "**Assumming the P(High ALC) = 0.25. In a class of 10, What is the probability of finding 5 students with High ACL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.binom.pmf(k=5, n=10, p=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probs_n(n):\n",
    "    fig, ax = plt.subplots(1,2, figsize = (14,4))\n",
    "    ax[0].bar(left=arange(n+1), height=stats.binom.pmf(k=arange(n+1), n=n, p=0.25))\n",
    "    ax[0].set_xticks(arange(n+1))\n",
    "    ax[0].set_title('Probability mass function')\n",
    "    ax[1].plot(stats.binom.cdf(k=range(n+1), n=n, p=0.25))\n",
    "    ax[1].set_xticks(arange(n+1))\n",
    "    ax[1].set_title('Cumulative distribution function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probs_n(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Hypothesis Testing framework\n",
    "\n",
    "**1. Setting up two competing hypotheses** - Each hypothesis test includes two hypothesis about the population.  One is the null hypothesis, notated as Ho, which is a statement of a particular parameter value.  This hypothesis is assumed to be true until there is evidence to suggest otherwise.  The second hypothesis is called the alternative, or research, hypothesis, notated as Ha.  The alternative hypothesis is a statement of a range of alternative values in which the parameter may fall.  One must also check that any assumptions (conditions) needed to run the test have been satisfied e.g. normality of data, independence, and number of success and failure outcomes.\n",
    "\n",
    "**2. Set in advanced some level of significance, called alpha.**  This value is used as a probability cutoff for making decisions about the null hypothesis.  As we will learn later, this alpha value represents the probability we are willing to place on our test for making an incorrect decision in regards to rejecting the null hypothesis.  The most common alpha value is 0.05  or 5%. Other popular choices are 0.01 (1%) and  0.1 (10%).\n",
    "\n",
    "**3. Calculate a test statistic and the p-value (or find rejection region)** Gather sample data and calculate a test statistic where the sample statistic is compared to the parameter value.  The test statistic is calculated under the assumption the null hypothesis is true, and incorporates a measure of standard error and assumptions (conditions) related to the sampling distribution.  Such assumptions could be normality of data, independence, and number of success and failure outcomes. A p-value is found by using the test statistic to calculate the probability of the sample data producing such a test statistic or one more extreme.  The rejection region is found by using alpha to find a critical value; the rejection region is the area that is more extreme than the critical value.\n",
    "\n",
    "**4. Make a test decision about the null hypothesis -**  In this step we decide to either reject the null hypothesis or decide to fail to reject the null hypothesis.  Notice we do not make a decision where we will accept the null hypothesis. \n",
    "\n",
    "**5. State an overall conclusion -** Once we have found the p-value or rejection region, and made a statistical decision about the null hypothesis (i.e. we will reject the null or fail to reject the null).  Following this decision, we want to summarize our results into an overall conclusion for our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Some Statistical test from <code>scipy.stats</code></h2>\n",
    "\n",
    "* kurtosistest(a[, axis, nan_policy])\tTests whether a dataset has normal kurtosis\n",
    "* normaltest(a[, axis, nan_policy])\tTests whether a sample differs from a normal distribution.\n",
    "* skewtest(a[, axis, nan_policy])\tTests whether the skew is different from the normal distribution.\n",
    "* pearsonr(x, y)\tCalculates a Pearson correlation coefficient and the p-value for testing non-correlation.\n",
    "* ttest_1samp(a, popmean[, axis, nan_policy])\tCalculates the T-test for the mean of ONE group of scores.\n",
    "* ttest_1samp(a, popmean[, axis, nan_policy])\tCalculates the T-test for the mean of ONE group of scores.\n",
    "* ttest_ind(a, b[, axis, equal_var, nan_policy])\tCalculates the T-test for the means of two independent samples of scores.\n",
    "* ttest_ind_from_stats(mean1, std1, nobs1, ...)\tT-test for means of two independent samples from descriptive statistics.\n",
    "* ttest_rel(a, b[, axis, nan_policy])\tCalculates the T-test on TWO RELATED samples of scores, a and b.\n",
    "* kstest(rvs, cdf[, args, N, alternative, mode])\tPerform the Kolmogorov-Smirnov test for goodness of fit.\n",
    "* chisquare(f_obs[, f_exp, ddof, axis])\tCalculates a one-way chi square test.\n",
    "* ansari(x, y)\tPerform the Ansari-Bradley test for equal scale parameters\n",
    "* bartlett(*args)\tPerform Bartlettâ€™s test for equal variances\n",
    "* levene(*args, **kwds)\tPerform Levene test for equal variances.\n",
    "* shapiro(x[, a, reta])\tPerform the Shapiro-Wilk test for normality.\n",
    "* anderson(x[, dist])\tAnderson-Darling test for data coming from a particular distribution\n",
    "* anderson_ksamp(samples[, midrank])\tThe Anderson-Darling test for k-samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the population variances equal in the two groups of students (Low vs. High alcohol consumption)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the Bartetts's test whose Null Hypothesis is that the variances are equal. We will use a significance level of 5.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.groupby('acl')['G3'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_low_acl = student['G3'][student['acl']=='Low']\n",
    "grades_high_acl = student['G3'][student['acl']=='High']\n",
    "stats.bartlett(grades_low_acl, grades_high_acl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the test we **cannot** reject the Null hypothesis of equal variances, so we will use assume that the two groups are samples from a population with the same variances. This information will be useful in our next test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does alcohol consumption affect academic performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (14,4))\n",
    "sns.boxplot(x='acl', y='G3', data=student, ax=axes[0])\n",
    "sns.pointplot(x='acl', y='G3', data=student, ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualizations sugest there is a difference between the means of the final grade of the two groups. Now we will perform a formal statistical test to confirm the hypothesis that students with High alcohol consumption level perform worse than the students with Low alcohol consumption level.\n",
    "\n",
    "> **Null Hypothesis: for both groups (High and Low ACL) the population means of the final grade are equal.**\n",
    "\n",
    ">  **Alternative Hypothesis: The population means of the final grades are different.**\n",
    "\n",
    "A common test to apply in for these cases is the two-sample t-test, which is used to determine if two population means are equal. \n",
    "\n",
    "All statistical tests have assumptions that must be checked for their conclusions to be valid, for these test the assumptions are:\n",
    "\n",
    "1. **Independent samples**: we will assume that the method for collecting the data assured that the answers given by the students are independent.\n",
    "2. **Large enough sample size or observations come from a normally-distributed population**: this assumption is required if we are working with small samples (less than 30), since in the smaller group we have 166 observations we can say that we have a \"large enough\" sample.\n",
    "3. **Variances are equal**\n",
    "\n",
    "In addition this test have two versions: one assuming equal variances and the other assumming unequal variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the test we can not reject the Null hypothesis of equal variances, so we will use assume that the two samples come from a population with the same population variances. Time to perform our t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(grades_low_acl, grades_high_acl, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we got such a low p-value we can reject the Null hypothesis of equal means for the two groups at a level of significance of 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Conclusion: there is a statistical significant difference between the grades in the two analyzed groups, since the mean for the group with high alcohol consumption is less than the mean of the other group, the results suggest that alcohol consumption has a negative impact on students' academic performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do male teenagers drink more than female teenagers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (14,4))\n",
    "student['gender'].value_counts().plot(kind='bar', ax=axes[0], title='Gender')\n",
    "student['acl'].value_counts().plot(kind='bar', ax=axes[1], title='Alcohol Consumption Level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_acl_table = pd.crosstab(student['acl'], student['gender'])\n",
    "gender_acl_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (14,4))\n",
    "gender_acl_table.plot(kind='bar', stacked=True, ax=axes[0]);\n",
    "(100*(gender_acl_table.T/gender_acl_table.apply(sum, axis=1)).T).plot(kind='bar', stacked=True, ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-square test of independence of variables in a contingency table.\n",
    "\n",
    "This function computes the chi-square statistic and p-value for the hypothesis test of independence of the observed frequencies in the contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_stat, p_value, dof, expected = stats.chi2_contingency(gender_acl_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_table = pd.DataFrame(expected, index=['High','Low'], columns=['F','M'])\n",
    "expected_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (14,4))\n",
    "(100*(gender_acl_table.T/gender_acl_table.apply(sum, axis=1)).T)\\\n",
    ".plot(kind='bar', stacked=True, title='Observed', ax=axes[0]);\n",
    "\n",
    "(100*(expected_table.T/expected_table.apply(sum, axis=1)).T)\\\n",
    ".plot(kind='bar', stacked=True, title='Expected under NO relation', ax=axes[1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "173px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
